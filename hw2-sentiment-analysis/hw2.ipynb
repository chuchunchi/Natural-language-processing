{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(label):\n",
    "    if label == \"neutral\":\n",
    "        return 0\n",
    "    elif label == \"anger\":\n",
    "        return 1\n",
    "    elif label == \"joy\":\n",
    "        return 2\n",
    "    elif label == \"surprise\":\n",
    "        return 3\n",
    "    elif label == \"sadness\":\n",
    "        return 4\n",
    "    elif label == \"disgust\":\n",
    "        return 5\n",
    "    elif label == \"fear\":\n",
    "        return 6\n",
    "\n",
    "s2idx = {\"Chandler\":0, \"The Interviewer\":1, \"Joey\":2, \"Rachel\":3, \"Monica\":4, \"Phoebe\":5, \"Ross\":6, \"Jade\":7, \"Mona\":8, \"Charlie\":9}\n",
    "    \n",
    "    \n",
    "def encode(text, word2index, label, N, speaker):\n",
    "    tokenized = word_tokenize(text)\n",
    "    encoded = [0]*N\n",
    "    enc1 = [word2index.get(word) for word in tokenized]\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    if(speaker in s2idx):\n",
    "        idx = s2idx[speaker]\n",
    "    else:\n",
    "        idx = 10\n",
    "    encoded.insert(0,idx)\n",
    "    return (encoded,label)\n",
    "\n",
    "def encode_test(text, word2index, N, speaker):\n",
    "    tokenized = word_tokenize(text)\n",
    "    for i,word in enumerate(tokenized):\n",
    "        if word2index.get(word)==None:\n",
    "            tokenized[i]='unk'\n",
    "\n",
    "    encoded = [0]*N\n",
    "    enc1 = [word2index.get(word) for word in tokenized]\n",
    "\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    if(speaker in s2idx):\n",
    "        idx = s2idx[speaker]\n",
    "    else:\n",
    "        idx = 10\n",
    "    encoded.insert(0,idx)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text = batch[0].to(device)\n",
    "        target = batch[1]\n",
    "        target = target.type(torch.LongTensor)\n",
    "        target = target.to(device)\n",
    "        preds = model(text)\n",
    "        loss = criterion(preds, target)\n",
    "        _, pred = torch.max(preds, 1)\n",
    "        acc = accuracy_score(pred.tolist(), target.tolist())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    for batch in iterator:\n",
    "        text = batch[0].to(device)\n",
    "        target = batch[1]\n",
    "        target = target.type(torch.LongTensor)\n",
    "        target = target.to(device)\n",
    "        preds = model(text)\n",
    "        loss = criterion(preds, target)\n",
    "        _, pred = torch.max(preds, 1)\n",
    "        acc = accuracy_score(pred.tolist(), target.tolist())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_HW2dataset.csv')\n",
    "dev_df = pd.read_csv('dev_HW2dataset.csv')\n",
    "\n",
    "train_df=train_df[['Emotion','Utterance','Speaker']]\n",
    "dev_df=dev_df[['Emotion','Utterance','Speaker']]\n",
    "\n",
    "train_set = list(train_df.to_records(index=False))\n",
    "dev_set = list(dev_df.to_records(index=False))\n",
    "\n",
    "counts = Counter()\n",
    "for ds in [train_set, dev_set]:\n",
    "    for label,text,speaker in ds:\n",
    "        counts.update(word_tokenize(text))\n",
    "\n",
    "word2index = {'unk':0}\n",
    "for i,word in enumerate(counts.keys()):\n",
    "    word2index[word] = i+1\n",
    "index2word = {v:k for k,v in word2index.items()}\n",
    "\n",
    "train_encoded = [(encode(Utterance,word2index,label_map(label),12,s)) for label, Utterance, s in train_set]\n",
    "dev_encoded   = [(encode(Utterance,word2index,label_map(label),12,s)) for label, Utterance,s in dev_set]\n",
    "\n",
    "train_x = np.array([tweet for tweet, label in train_encoded])\n",
    "train_y = np.array([label for tweet, label in train_encoded])\n",
    "dev_x = np.array([tweet for tweet, label in dev_encoded])\n",
    "dev_y = np.array([label for tweet, label in dev_encoded])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "dev_ds = TensorDataset(torch.from_numpy(dev_x), torch.from_numpy(dev_y))\n",
    "\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "dev_dl = DataLoader(dev_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_x = np.append(train_x, dev_x, axis=0)\n",
    "total_y = np.append(train_y, dev_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(word2index)\n",
    "dimension_model = 128\n",
    "num_layers = 5\n",
    "hidden_size = 60\n",
    "linear_hidden_size = 30\n",
    "classes = 7\n",
    "dropout = 0.2        \n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(src_vocab_size, dimension_model)                        \n",
    "        self.lstm = torch.nn.LSTM(input_size=dimension_model, hidden_size=hidden_size,num_layers=num_layers,dropout=dropout)\n",
    "        self.linear = torch.nn.Linear(hidden_size, linear_hidden_size)\n",
    "        self.linear1 = torch.nn.Linear(linear_hidden_size, classes)\n",
    "    def forward(self,data):\n",
    "        x = self.embed(data)                          \n",
    "        x,(h_n, c_n) = self.lstm(x.transpose(0, 1))  \n",
    "                                                         \n",
    "                                                    \n",
    "        x = self.linear(x[-1])                          \n",
    "        x = self.linear1(x)                            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "def cv_idx():\n",
    "    idxarr = np.arange(len(total_y))\n",
    "    np.random.shuffle(idxarr)\n",
    "    Q = int( len(total_y) / k )\n",
    "    #print(Q)\n",
    "    rem = len(total_y) % k\n",
    "    \n",
    "    ret = [[] for _ in range(k)]\n",
    "    foldsize = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        if k < rem:\n",
    "            foldsize[i] = Q + 1\n",
    "        else:\n",
    "            foldsize[i] = Q\n",
    "    for i in range(k):\n",
    "        train = []\n",
    "        val = []\n",
    "        start = 0\n",
    "        for j in range(k): \n",
    "            if j == i:\n",
    "                for s in range(int(foldsize[j])):\n",
    "                    val.append(idxarr[start])\n",
    "                    start += 1\n",
    "            else:\n",
    "                for s in range(int(foldsize[j])):\n",
    "                    train.append(idxarr[start])\n",
    "                    start += 1\n",
    "        ret[i].append(np.array(train))\n",
    "        ret[i].append(np.array(val))\n",
    "    return ret\n",
    "\n",
    "kfold_data = cv_idx()\n",
    "\n",
    "def cross_val(i):\n",
    "    batch_size = 32\n",
    "    train_x = total_x[kfold_data[i][0]]\n",
    "    train_y = total_y[kfold_data[i][0]]\n",
    "    dev_x = total_x[kfold_data[i][1]]\n",
    "    dev_y = total_y[kfold_data[i][1]]\n",
    "    train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "    dev_ds = TensorDataset(torch.from_numpy(dev_x), torch.from_numpy(dev_y))\n",
    "\n",
    "    train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "    dev_dl = DataLoader(dev_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "    return train_dl, dev_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 1.309, Train Acc: 55.11%, Val. Loss: 1.265, Val. Acc: 56.71%\n",
      "Epoch: 02, Train Loss: 0.907, Train Acc: 70.21%, Val. Loss: 0.856, Val. Acc: 72.30%\n",
      "Epoch: 03, Train Loss: 0.594, Train Acc: 81.50%, Val. Loss: 0.549, Val. Acc: 82.96%\n",
      "Epoch: 04, Train Loss: 0.430, Train Acc: 86.47%, Val. Loss: 0.387, Val. Acc: 87.68%\n",
      "Epoch: 05, Train Loss: 0.328, Train Acc: 89.59%, Val. Loss: 0.285, Val. Acc: 90.64%\n",
      "Epoch: 06, Train Loss: 0.266, Train Acc: 91.49%, Val. Loss: 0.227, Val. Acc: 92.74%\n",
      "Epoch: 07, Train Loss: 0.226, Train Acc: 92.69%, Val. Loss: 0.197, Val. Acc: 93.56%\n",
      "Epoch: 08, Train Loss: 0.191, Train Acc: 93.79%, Val. Loss: 0.149, Val. Acc: 95.22%\n",
      "Epoch: 09, Train Loss: 0.164, Train Acc: 94.79%, Val. Loss: 0.132, Val. Acc: 95.82%\n",
      "Epoch: 10, Train Loss: 0.147, Train Acc: 95.22%, Val. Loss: 0.116, Val. Acc: 96.21%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "model = LSTM().to(device)                           \n",
    "criterion = torch.nn.CrossEntropyLoss()                  \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr) \n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_t_loss = 0\n",
    "    total_v_loss = 0\n",
    "    total_t_acc = 0\n",
    "    total_v_acc = 0\n",
    "    for i in range(k):\n",
    "        train_dl, dev_dl = cross_val(i)\n",
    "        train_loss, train_acc = train(model, train_dl,\n",
    "                                    optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, dev_dl,\n",
    "                                        criterion)\n",
    "        total_t_loss += train_loss\n",
    "        total_v_loss += valid_loss\n",
    "        total_t_acc += train_acc\n",
    "        total_v_acc += valid_acc\n",
    "    total_t_loss /= k\n",
    "    total_v_loss /= k\n",
    "    total_t_acc /= k\n",
    "    total_v_acc /= k\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {total_t_loss:.3f}, Train Acc: {total_t_acc * 100:.2f}%, Val. Loss: {total_v_loss:.3f}, Val. Acc: {total_v_acc * 100:.2f}%')    \n",
    "    if best_acc <= total_v_acc:\n",
    "        best_acc = total_v_acc\n",
    "        PATH=f\"epoch{epoch+1}_val.accuracy{total_v_acc:.3f}%.pt\"\n",
    "        torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': total_v_acc,\n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_HW2dataset.csv')\n",
    "test_df=test_df[['Utterance','Speaker']]\n",
    "#test_set = test_df.values.tolist()\n",
    "test_set = list(test_df.to_records(index=False))\n",
    "#print(test_set)\n",
    "test_encoded=[]\n",
    "test_encoded+=[encode_test(Utterance, word2index, 10, s) for Utterance,s in test_set]\n",
    "test_x = np.array(test_encoded)\n",
    "test_ds = TensorDataset(torch.from_numpy(test_x))\n",
    "test_dl = DataLoader(test_ds, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model = LSTM().to(device)                               \n",
    "criterion = torch.nn.CrossEntropyLoss()                  \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr) \n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.eval()\n",
    "predict=[]\n",
    "for deta in test_dl:\n",
    "    text = deta[0].to(device)\n",
    "    preds = model(text)\n",
    "    _, pred = torch.max(preds, 1)\n",
    "    predict.append(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400\n"
     ]
    }
   ],
   "source": [
    "print(len(predict))\n",
    "ans = [[i, pre] for [i,pre] in enumerate(predict)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "h = ['index', 'emotion']\n",
    "with open('predict.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(h)\n",
    "    writer.writerows(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab78bb3c465f8a9a3b2b3033a0b53f8ddb3d4f2700280c40496e40ae689e591d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
