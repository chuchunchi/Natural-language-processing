{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11895,"status":"ok","timestamp":1673236695627,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"XIqgylAIis_f","outputId":"3f8265d8-24f1-4fa7-a418-48063b05a514"},"outputs":[],"source":["%pip install transformers==4.15.0"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5069,"status":"ok","timestamp":1673236700688,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"l-selOuvQwWK"},"outputs":[],"source":["import csv\n","import os\n","import argparse\n","import random\n","from tqdm import tqdm, trange\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","\n","#from modeling import BertConfig, BertForSequenceClassification\n","from transformers import BertForSequenceClassification, BertConfig, AdamW, BertTokenizer\n","\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1991,"status":"ok","timestamp":1673236702675,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"uwjFX_2eQwWL"},"outputs":[],"source":["n_class = 4\n","BATCH_SIZE = 3\n","lr = 5e-5\n","EPOCH = 1\n","data_dir = \".\"\n","vocab_file = \"vocab.txt\"\n","max_seq_length = 128\n","\n","tokenizer = BertTokenizer(\n","        vocab_file=vocab_file, do_lower_case=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673237773621,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"oDGAN2_sQwWM"},"outputs":[],"source":["class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None, text_c=None):\n","        \"\"\"Constructs a InputExample.\n","\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence.\n","            Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.text_c = text_c\n","        self.label = label\n","\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id\n","\n","\n","class c3Processor():\n","    def __init__(self):\n","        random.seed(42)\n","        self.D = [[], [], []]\n","\n","        for sid in range(3):\n","            data = []\n","            with open(\"data/\"+[\"train_HW3dataset.json\", \"dev_HW3dataset.json\", \"test_HW3dataset.json\"][sid], \"r\", encoding=\"utf8\") as f:\n","                data += json.load(f)\n","            if sid == 0:\n","                random.shuffle(data)\n","            for i in range(len(data)):\n","                for j in range(len(data[i][1])):\n","                    d = ['\\n'.join(data[i][0]).lower(), data[i][1][j][\"question\"].lower()]\n","                    for k in range(len(data[i][1][j][\"choice\"])):\n","                        d += [data[i][1][j][\"choice\"][k].lower()]\n","                    for k in range(len(data[i][1][j][\"choice\"]), 4):\n","                        d += ['']\n","                    if sid!=2:\n","                        d += [data[i][1][j][\"answer\"].lower()]\n","                    else:\n","                        d += [data[i][1][j][\"choice\"][0].lower()]\n","                    self.D[sid] += [d]\n","    \n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","                self.D[0], \"train\")\n","\n","    def get_test_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","                self.D[2], \"test\")\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","                self.D[1], \"dev\")\n","\n","    def get_labels(self):\n","        \"\"\"See base class.\"\"\"\n","        return [\"0\", \"1\", \"2\", \"3\"]\n","\n","    def _create_examples(self, data, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        examples = []\n","        for (i, d) in enumerate(data):\n","            for k in range(4):\n","                if data[i][2+k] == data[i][6]:\n","                    answer = str(k)\n","                    \n","            label = answer\n","\n","            for k in range(4):\n","                guid = \"%s-%s-%s\" % (set_type, i, k)\n","                text_a = data[i][0]\n","                text_b = data[i][k+2]\n","                text_c = data[i][1]\n","                examples.append(\n","                        InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label, text_c=text_c))\n","            \n","        return examples\n","\n","\n","\n","def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n","\n","    print(\"#examples\", len(examples))\n","\n","    label_map = {}\n","    for (i, label) in enumerate(label_list):\n","        label_map[label] = i\n","\n","    features = [[]]\n","    for (ex_index, example) in enumerate(examples):\n","        tokens_a = tokenizer.tokenize(example.text_a)\n","\n","        tokens_b = tokenizer.tokenize(example.text_b)\n","\n","        tokens_c = tokenizer.tokenize(example.text_c)\n","\n","        _truncate_seq_tuple(tokens_a, tokens_b, tokens_c, max_seq_length - 4)\n","        tokens_b = tokens_c + [\"[SEP]\"] + tokens_b\n","\n","        tokens = []\n","        segment_ids = []\n","        tokens.append(\"[CLS]\")\n","        segment_ids.append(0)\n","        for token in tokens_a:\n","            tokens.append(token)\n","            segment_ids.append(0)\n","        tokens.append(\"[SEP]\")\n","        segment_ids.append(0)\n","\n","        if tokens_b:\n","            for token in tokens_b:\n","                tokens.append(token)\n","                segment_ids.append(1)\n","            tokens.append(\"[SEP]\")\n","            segment_ids.append(1)\n","\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","        # tokens are attended to.\n","        input_mask = [1] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","            segment_ids.append(0)\n","\n","        label_id = label_map[example.label]\n","\n","        features[-1].append(\n","                InputFeatures(\n","                        input_ids=input_ids,\n","                        input_mask=input_mask,\n","                        segment_ids=segment_ids,\n","                        label_id=label_id))\n","        if len(features[-1]) == n_class:\n","            features.append([])\n","\n","    if len(features[-1]) == 0:\n","        features = features[:-1]\n","    print('#features', len(features))\n","    return features\n","\n","\n","\n","\n","def _truncate_seq_tuple(tokens_a, tokens_b, tokens_c, max_length):\n","    \"\"\"Truncates a sequence tuple in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b) + len(tokens_c)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) >= len(tokens_b) and len(tokens_a) >= len(tokens_c):\n","            tokens_a.pop()\n","        elif len(tokens_b) >= len(tokens_a) and len(tokens_b) >= len(tokens_c):\n","            tokens_b.pop()\n","        else:\n","            tokens_c.pop()            \n","\n","\n","def accuracy(out, labels):\n","    outputs = np.argmax(out, axis=1)\n","    print(outputs,labels)\n","    return np.sum(outputs==labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191,"referenced_widgets":["20cf38748065484299274df7906a9c51","6ebd8a5c40b343e3ad1faf917cbe096e","6a330284e55344d2a1da1997d40a5b05","d2f64258ee56439e9eb56de117ce2f81","89445d3d2cc14dbcab11be512834091b","77dbc3ff9c524894a4f43973cd89e8ae","d0f5873b8a704824be8586e6c324394e","84418d58230447f5a8dd1530188e02cc","a91ac2b459414981891c47f848d0fcae","2bf6e63c0e5847c5b0cb5957136069d9","e8296e9ae84f41d28922474a26d99ce4","6ce53b6c04ac4bdba309138129342cae","9c795b1152d0438e8761ed4e333e9b7b","9099869a11b44f7f9545c866847fc251","2d4c1d9d44674354b3af547cf3ae62d5","2c1114716d0841f09dfe4ed5d1b9ca27","e1242fc7d98d4a3aa853585f35d11a98","0435291ced984a2483a23000a2771674","81d7d071bc7e4ea2820a146d337a2ab9","67a0d6596acb465390dfa4aebb58aee9","063c806a853c48ff910b9b7de5ed584c","493b1ee3e2034e9b891f2bcf2bc24c25"]},"executionInfo":{"elapsed":25259,"status":"ok","timestamp":1673236727928,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"fYg2o-JoQwWP","outputId":"76bb7b50-f281-4621-aee1-f885c6366abe"},"outputs":[],"source":["do_train = True\n","do_eval = True\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","\n","\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if n_gpu > 0:\n","    torch.cuda.manual_seed_all(42)\n","\n","bert_config = BertConfig.from_json_file(\"bert_config.json\")\n","\n","processor = c3Processor()\n","label_list = processor.get_labels()\n","\n","\n","\n","train_examples = None\n","num_train_steps = None\n","if do_train:\n","    train_examples = processor.get_train_examples(data_dir)\n","    num_train_steps = int(\n","        len(train_examples) / n_class / BATCH_SIZE * EPOCH)\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-chinese', return_dict=True, num_labels=4)\n","model.to(device)\n","model.num_labels = 4\n","# nnv = NNView().to(device)\n","model.classifier = nn.Linear(model.config.hidden_size, 1).to(device)\n","\n","if n_gpu > 1:\n","    model = torch.nn.DataParallel(model)\n","\n","no_decay = ['bias']\n","optimizer_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if n not in no_decay], 'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if n in no_decay], 'weight_decay_rate': 0.0}\n","    ]\n","\n","optimizer = AdamW(optimizer_parameters,\n","                        lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59951,"status":"ok","timestamp":1673236787827,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"qAvQqNr_UnkD","outputId":"8ada0947-bf81-4808-d6a6-b711678155f4"},"outputs":[],"source":["train_features = convert_examples_to_features(\n","        train_examples, label_list, max_seq_length, tokenizer)\n","eval_examples = processor.get_dev_examples(data_dir)\n","eval_features = convert_examples_to_features(\n","    eval_examples, label_list, max_seq_length, tokenizer)\n","\n","input_ids = []\n","input_mask = []\n","segment_ids = []\n","label_id = []\n","\n","for f in eval_features:\n","    input_ids.append([])\n","    input_mask.append([])\n","    segment_ids.append([])\n","    for i in range(n_class):\n","        input_ids[-1].append(f[i].input_ids)\n","        input_mask[-1].append(f[i].input_mask)\n","        segment_ids[-1].append(f[i].segment_ids)\n","    label_id.append([f[0].label_id])                \n","\n","all_input_ids = torch.tensor(input_ids, dtype=torch.long)\n","all_input_mask = torch.tensor(input_mask, dtype=torch.long)\n","all_segment_ids = torch.tensor(segment_ids, dtype=torch.long)\n","all_label_ids = torch.tensor(label_id, dtype=torch.long)\n","\n","eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","eval_sampler = SequentialSampler(eval_data)\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597774,"status":"ok","timestamp":1673238749259,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"BZMegTJvQwWQ","outputId":"70170f48-4a95-488b-8bff-4390dedd6b2b"},"outputs":[],"source":["best_accuracy = 0\n","print(\"***** Running training *****\")\n","print(\"  Num examples = %d\", len(train_examples))\n","print(\"  Batch size = %d\", BATCH_SIZE)\n","print(\"  Num steps = %d\", num_train_steps)\n","\n","input_ids = []\n","input_mask = []\n","segment_ids = []\n","label_id = []\n","for f in train_features:\n","    input_ids.append([])\n","    input_mask.append([])\n","    segment_ids.append([])\n","    for i in range(n_class):\n","        input_ids[-1].append(f[i].input_ids)\n","        input_mask[-1].append(f[i].input_mask)\n","        segment_ids[-1].append(f[i].segment_ids)\n","    label_id.append([f[0].label_id])                \n","\n","all_input_ids = torch.tensor(input_ids, dtype=torch.long)\n","all_input_mask = torch.tensor(input_mask, dtype=torch.long)\n","all_segment_ids = torch.tensor(segment_ids, dtype=torch.long)\n","all_label_ids = torch.tensor(label_id, dtype=torch.long)\n","\n","train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","\n","for _ in range(EPOCH):\n","    model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_ids = batch\n","        targetlen = input_ids.size(2)\n","        input_ids = input_ids.view(-1,targetlen)\n","        input_mask = input_mask.view(-1,targetlen)\n","        segment_ids = segment_ids.view(-1,targetlen)\n","        \n","        # print(label_ids.shape)\n","        # print(input_ids.shape)\n","        outputs = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids)\n","        loss = outputs.loss\n","        if n_gpu > 1:\n","            loss = loss.mean() # mean() to average on multi-gpu.\n","        loss.backward()\n","        tr_loss += loss.item()\n","        nb_tr_examples += input_ids.size(0)\n","        nb_tr_steps += 1\n","        optimizer.step()\n","        model.zero_grad()\n","\n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    logits_all = []\n","    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n","        input_ids = input_ids.to(device)\n","        input_mask = input_mask.to(device)\n","        segment_ids = segment_ids.to(device)\n","        label_ids = label_ids.to(device)\n","        targetlen = input_ids.size(2)\n","        input_ids = input_ids.view(-1,targetlen)\n","        input_mask = input_mask.view(-1,targetlen)\n","        segment_ids = segment_ids.view(-1,targetlen)\n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids)\n","            tmp_eval_loss = outputs.loss\n","            logits = outputs.logits\n","\n","        logits = logits.detach().cpu().numpy()\n","        logits = logits.reshape((-1,n_class))\n","        label_ids = label_ids.to('cpu').numpy()\n","        for i in range(len(logits)):\n","            logits_all += [logits[i]]\n","        \n","        tmp_eval_accuracy = accuracy(logits, label_ids.reshape(-1))\n","\n","        eval_loss += tmp_eval_loss.mean().item()\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        nb_eval_examples += input_ids.size(0)\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_examples\n","\n","    if do_train:\n","        result = {'eval_loss': eval_loss,\n","                    'eval_accuracy': eval_accuracy,\n","                    'loss': tr_loss/nb_tr_steps}\n","    else:\n","        result = {'eval_loss': eval_loss,\n","                    'eval_accuracy': eval_accuracy}\n","\n","    print(\"***** Eval results *****\")\n","    for key in sorted(result.keys()):\n","        print(\"  %s = %s\", key, str(result[key]))\n","\n","    if eval_accuracy >= best_accuracy:\n","        torch.save(model.state_dict(), \"model_best.pt\")\n","        best_accuracy = eval_accuracy\n","        \n","model.load_state_dict(torch.load(\"model_best.pt\"))\n","torch.save(model.state_dict(), \"model.pt\")\n","\n","model.load_state_dict(torch.load(\"model.pt\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1673237393218,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"GE0im1tZnUSw","outputId":"981146c9-d15f-4a55-faf7-54dbe546d950"},"outputs":[],"source":["print(logits.shape)\n","print(label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":17370,"status":"error","timestamp":1673237798440,"user":{"displayName":"紀竺均","userId":"10396067312214412745"},"user_tz":-480},"id":"o1GA_W-SQwWR","outputId":"38c5101a-d40f-4a83-e627-5cc5b74e6c5e"},"outputs":[],"source":["global_step = 0\n","\n","print(\"***** Running evaluation *****\")\n","print(\"  Num examples = %d\", len(eval_examples))\n","print(\"  Batch size = %d\", BATCH_SIZE)\n","\n","model.eval()\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","logits_all = []\n","\n","for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n","    \n","    input_ids = input_ids.to(device)\n","    input_mask = input_mask.to(device)\n","    segment_ids = segment_ids.to(device)\n","    label_ids = label_ids.to(device)\n","    targetlen = input_ids.size(2)\n","    input_ids = input_ids.view(-1,targetlen)\n","    input_mask = input_mask.view(-1,targetlen)\n","    segment_ids = segment_ids.view(-1,targetlen)\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids)\n","        tmp_eval_loss, logits = outputs.loss, outputs.logits\n","\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = label_ids.to('cpu').numpy()\n","    logits = logits.reshape((-1,n_class))\n","    for i in range(len(logits)):\n","        logits_all += [logits[i]]\n","    \n","    tmp_eval_accuracy = accuracy(logits, label_ids.reshape(-1))\n","    # print(logits.shape, label_ids.shape)\n","\n","    eval_loss += tmp_eval_loss.mean().item()\n","    eval_accuracy += tmp_eval_accuracy\n","\n","    nb_eval_examples += input_ids.size(0)\n","    nb_eval_steps += 1\n","\n","eval_loss = eval_loss / nb_eval_steps\n","eval_accuracy = eval_accuracy / nb_eval_examples\n","\n","if do_train:\n","    result = {'eval_loss': eval_loss,\n","                'eval_accuracy': eval_accuracy,\n","                'global_step': global_step,\n","                'loss': tr_loss/nb_tr_steps}\n","else:\n","    result = {'eval_loss': eval_loss,\n","                'eval_accuracy': eval_accuracy}\n","\n","eval_examples = processor.get_test_examples(data_dir)\n","eval_features = convert_examples_to_features(\n","    eval_examples, label_list, max_seq_length, tokenizer)\n","\n","print(\"***** Running evaluation *****\")\n","print(\"  Num examples = %d\", len(eval_examples))\n","print(\"  Batch size = %d\", BATCH_SIZE)\n","\n","input_ids = []\n","input_mask = []\n","segment_ids = []\n","label_id = []\n","\n","for f in eval_features:\n","    input_ids.append([])\n","    input_mask.append([])\n","    segment_ids.append([])\n","    for i in range(n_class):\n","        input_ids[-1].append(f[i].input_ids)\n","        input_mask[-1].append(f[i].input_mask)\n","        segment_ids[-1].append(f[i].segment_ids)\n","    label_id.append([f[0].label_id])                \n","\n","all_input_ids = torch.tensor(input_ids, dtype=torch.long)\n","all_input_mask = torch.tensor(input_mask, dtype=torch.long)\n","all_segment_ids = torch.tensor(segment_ids, dtype=torch.long)\n","all_label_ids = torch.tensor(label_id, dtype=torch.long)\n","\n","eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","eval_sampler = SequentialSampler(eval_data)\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=BATCH_SIZE)\n","\n","model.eval()\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","logits_all = []\n","for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n","    input_ids = input_ids.to(device)\n","    input_mask = input_mask.to(device)\n","    segment_ids = segment_ids.to(device)\n","    label_ids = label_ids.to(device)\n","    targetlen = input_ids.size(2)\n","    input_ids = input_ids.view(-1,targetlen)\n","    input_mask = input_mask.view(-1,targetlen)\n","    segment_ids = segment_ids.view(-1,targetlen)\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids)\n","        tmp_eval_loss = outputs.loss\n","        logits = outputs.logits\n","    \n","    logits = logits.detach().cpu().numpy()\n","    label_ids = label_ids.to('cpu').numpy()\n","    logits = logits.reshape((-1,n_class))\n","    for i in range(len(logits)):\n","        logits_all += [logits[i]]\n","    \n","    tmp_eval_accuracy = accuracy(logits, label_ids.reshape(-1))\n","\n","    eval_loss += tmp_eval_loss.mean().item()\n","    eval_accuracy += tmp_eval_accuracy\n","\n","    nb_eval_examples += input_ids.size(0)\n","    nb_eval_steps += 1\n","\n","eval_loss = eval_loss / nb_eval_steps\n","eval_accuracy = eval_accuracy / nb_eval_examples\n","\n","predict_path = \"predict.csv\"\n","with open(predict_path, \"w\", newline='') as fcsv:\n","    writer = csv.writer(fcsv)\n","    writer.writerow(['index','answer'])\n","    for i in range(len(logits_all)):\n","        max_idx = 0.0\n","        max_val = -5.0\n","        for j in range(len(logits_all[i])):\n","            if(logits_all[i][j]>=max_val):\n","                max_val = logits_all[i][j]\n","                max_idx = j\n","            if j == len(logits_all[i])-1:\n","                writer.writerow([str(i), str(max_idx+1)])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"py37","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"a4aeef06c96536f965a1c98158cf14e4c8f4404974283f7a7e83e2c026e4c250"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0435291ced984a2483a23000a2771674":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"063c806a853c48ff910b9b7de5ed584c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20cf38748065484299274df7906a9c51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ebd8a5c40b343e3ad1faf917cbe096e","IPY_MODEL_6a330284e55344d2a1da1997d40a5b05","IPY_MODEL_d2f64258ee56439e9eb56de117ce2f81"],"layout":"IPY_MODEL_89445d3d2cc14dbcab11be512834091b"}},"2bf6e63c0e5847c5b0cb5957136069d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c1114716d0841f09dfe4ed5d1b9ca27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d4c1d9d44674354b3af547cf3ae62d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_063c806a853c48ff910b9b7de5ed584c","placeholder":"​","style":"IPY_MODEL_493b1ee3e2034e9b891f2bcf2bc24c25","value":" 393M/393M [00:10&lt;00:00, 74.8MB/s]"}},"493b1ee3e2034e9b891f2bcf2bc24c25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67a0d6596acb465390dfa4aebb58aee9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a330284e55344d2a1da1997d40a5b05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84418d58230447f5a8dd1530188e02cc","max":624,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a91ac2b459414981891c47f848d0fcae","value":624}},"6ce53b6c04ac4bdba309138129342cae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c795b1152d0438e8761ed4e333e9b7b","IPY_MODEL_9099869a11b44f7f9545c866847fc251","IPY_MODEL_2d4c1d9d44674354b3af547cf3ae62d5"],"layout":"IPY_MODEL_2c1114716d0841f09dfe4ed5d1b9ca27"}},"6ebd8a5c40b343e3ad1faf917cbe096e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77dbc3ff9c524894a4f43973cd89e8ae","placeholder":"​","style":"IPY_MODEL_d0f5873b8a704824be8586e6c324394e","value":"Downloading: 100%"}},"77dbc3ff9c524894a4f43973cd89e8ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d7d071bc7e4ea2820a146d337a2ab9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84418d58230447f5a8dd1530188e02cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89445d3d2cc14dbcab11be512834091b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9099869a11b44f7f9545c866847fc251":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81d7d071bc7e4ea2820a146d337a2ab9","max":411577189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67a0d6596acb465390dfa4aebb58aee9","value":411577189}},"9c795b1152d0438e8761ed4e333e9b7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1242fc7d98d4a3aa853585f35d11a98","placeholder":"​","style":"IPY_MODEL_0435291ced984a2483a23000a2771674","value":"Downloading: 100%"}},"a91ac2b459414981891c47f848d0fcae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0f5873b8a704824be8586e6c324394e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2f64258ee56439e9eb56de117ce2f81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf6e63c0e5847c5b0cb5957136069d9","placeholder":"​","style":"IPY_MODEL_e8296e9ae84f41d28922474a26d99ce4","value":" 624/624 [00:00&lt;00:00, 35.2kB/s]"}},"e1242fc7d98d4a3aa853585f35d11a98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8296e9ae84f41d28922474a26d99ce4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
